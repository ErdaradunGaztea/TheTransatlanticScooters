# Configure Spark on YARN
spark.master=yarn
spark.submit.deployMode=client
spark.yarn.jars=local:/usr/lib/spark/jars/*

# Dynamic allocation on YARN
spark.dynamicAllocation.enabled=false
spark.dynamicAllocation.minExecutors=1
spark.executor.instances=10000
spark.dynamicAllocation.maxExecutors=10000
spark.shuffle.service.enabled=true
spark.scheduler.minRegisteredResourcesRatio=0.0

# This undoes setting hive.execution.engine to tez in hive-site.xml
# It is not used by Spark
spark.hadoop.hive.execution.engine=mr

spark.rpc.message.maxSize=256

# On clusters without Kerberos integration, use unmanaged AM to speed-up Spark
# Context initialization and free-up 1 YARN container per-AM.
# On clusters integrated with Kerberos, YARN unmanaged AM setting will be
# disabled though.
spark.yarn.unmanagedAM.enabled=true

# Enable adaptive query execution, which re-optimizes the query plan
# in the middle of query execution, based on accurate runtime statistics.
spark.sql.adaptive.enabled=true
# Reorder joins when cost-based optimization enabled to improve performance.
spark.sql.cbo.joinReorder.enabled=true

spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2

spark.sql.autoBroadcastJoinThreshold=21m

spark.eventLog.enabled=true
spark.eventLog.dir=gs://dataproc-temp-europe-west1-752607501774-zh6iwnrr/f310665f-7bc2-4d4d-9065-80f0d5553c14/spark-job-history
spark.history.fs.logDirectory=gs://dataproc-temp-europe-west1-752607501774-zh6iwnrr/f310665f-7bc2-4d4d-9065-80f0d5553c14/spark-job-history

spark.history.fs.gs.outputstream.type=BASIC

spark.yarn.historyServer.address=spark-cluster-m:18080

# Enable using Hive as the metastore for Spark
spark.sql.catalogImplementation=hive

# User-supplied properties.
#Mon Jan 03 15:44:54 UTC 2022
spark.sql.cbo.enabled=true
spark.scheduler.mode=FAIR
spark.executorEnv.OPENBLAS_NUM_THREADS=1
spark.executor.instances=1
spark.ui.port=0
spark.executor.memory=5096m
spark.driver.memory=2048m
spark.executor.cores=1
spark.yarn.am.memory=1024m
spark.driver.maxResultSize=1024m

